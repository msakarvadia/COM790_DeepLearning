{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Batch norm and residual connections - HW 5",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoAyEW2Yp9B2"
      },
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYovBDSbwfYD"
      },
      "source": [
        "# 1. Batch normalization (3 points)\n",
        "\n",
        "Please make use of the model code from Homework 4 question 2 as you work on this question.\n",
        "\n",
        "1. If your model didn't use batch normalization, add it. If it already had batch normalization, remove it. How does the performance change? Please experiment with different learning rate values, since batch normalization can allow a different range of learning rates to work. You are welcome to write your own batch norm implementaiton or use a pre-existing one from mxnet or pytorch.\n",
        "1. Plot the squared L2 norm of gradients with respect to parameters over the course of training with and without batch normalization. To do this, you will need to compute the gradient of the loss over some data with respect to each parameter, square these gradients, and sum the result across all parameters. You can compute this value at each training step, or after each epoch. What difference does batch normalization make in terms of the squared L2 norm of gradients?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdHvFEuwp-vp",
        "outputId": "a05c40f4-1a7e-42d4-8345-0351458a98bf"
      },
      "source": [
        "transform = transforms.Compose(\r\n",
        "    [transforms.ToTensor(),\r\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\r\n",
        "\r\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\r\n",
        "                                        download=True, transform=transform)\r\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\r\n",
        "                                          shuffle=True, num_workers=2)\r\n",
        "\r\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\r\n",
        "                                       download=True, transform=transform)\r\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\r\n",
        "                                         shuffle=False, num_workers=2)\r\n",
        "\r\n",
        "classes = ('plane', 'car', 'bird', 'cat',\r\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytwx1cvJWuWp"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "# This comes from https://github.com/mtrencseni/pytorch-playground/blob/master/05-cifar-10/CIFAR-10.ipynb\r\n",
        "class Net(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Net, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(3,   64,  3)\r\n",
        "        self.conv1.add_module(\"BN1\", nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\r\n",
        "        self.conv2 = nn.Conv2d(64,  128, 3)\r\n",
        "        self.conv2.add_module(\"BN2\", nn.BatchNorm2d(num_features=128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\r\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3)\r\n",
        "        self.conv3.add_module(\"BN3\", nn.BatchNorm2d(num_features=256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\r\n",
        "        self.pool = nn.MaxPool2d(2, 2)\r\n",
        "        self.fc1 = nn.Linear(64 * 4 * 4, 128)\r\n",
        "        self.fc2 = nn.Linear(128, 256)\r\n",
        "        self.fc3 = nn.Linear(256, 10)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.pool(F.relu(self.conv1(x)))\r\n",
        "        x = self.pool(F.relu(self.conv2(x)))\r\n",
        "        x = self.pool(F.relu(self.conv3(x)))\r\n",
        "        x = x.view(-1, 64 * 4 * 4)\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.relu(self.fc2(x))\r\n",
        "        x = self.fc3(x)\r\n",
        "        return F.log_softmax(x, dim=1)\r\n",
        "\r\n",
        "net = Net()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bm09T_JqFJp"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5qOVFdNUhi3"
      },
      "source": [
        "Soruces:\r\n",
        "* https://discuss.pytorch.org/t/how-are-optimizer-step-and-loss-backward-related/7350\r\n",
        "* https://discuss.pytorch.org/t/how-to-interpret-the-grad-tensor-in-the-optimizer/34892\r\n",
        "* https://discuss.pytorch.org/t/a-problem-about-optimizer-param-groups-in-step-function/14463/3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HeLkC8FiqN_9",
        "outputId": "c47ba998-a8cc-474b-93c6-de26951fcce4"
      },
      "source": [
        "x_vals = range(1,26)\r\n",
        "l2_norms = []\r\n",
        "\r\n",
        "for epoch in range(25):  # loop over the dataset multiple times\r\n",
        "\r\n",
        "    running_loss = 0.0\r\n",
        "    for i, data in enumerate(trainloader, 0):\r\n",
        "        # get the inputs\r\n",
        "        inputs, labels = data\r\n",
        "\r\n",
        "        # zero the parameter gradients\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        # forward + backward + optimize\r\n",
        "        outputs = net(inputs)\r\n",
        "        loss = criterion(outputs, labels)\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        # print statistics\r\n",
        "        running_loss += loss.item()\r\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\r\n",
        "            print('[%d, %5d] loss: %.3f' %\r\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\r\n",
        "            running_loss = 0.0\r\n",
        "\r\n",
        "    #I think this is computing the right l2 norm:\r\n",
        "    #l2_norm = torch.sum(torch.square(optimizer.param_groups[0]['params'][0].grad)).item()\r\n",
        "    #print(l2_norm)\r\n",
        "    #l2_norms.append(l2_norm)\r\n",
        "    \r\n",
        "    grad_norm_sum = 0\r\n",
        "    for p in net.parameters():\r\n",
        "      if p.grad != None:\r\n",
        "        grad_norm_sum += torch.sum(torch.square(p.grad))\r\n",
        "    l2_norms.append(grad_norm_sum)\r\n",
        "    print(grad_norm_sum)\r\n",
        "    # THIS IS IMPORTANT: https://discuss.pytorch.org/t/difference-between-gradients-from-network-parameters-and-register-backward-hook/4580/3\r\n",
        "    # This is also important: https://discuss.pytorch.org/t/get-the-gradient-of-the-network-parameters/50575\r\n",
        "    \r\n",
        "plt.scatter(x_vals, l2_norms)\r\n",
        "plt.show()\r\n",
        "\r\n",
        "print('Finished Training')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.231\n",
            "[1,  4000] loss: 1.898\n",
            "[1,  6000] loss: 1.693\n",
            "[1,  8000] loss: 1.552\n",
            "[1, 10000] loss: 1.451\n",
            "[1, 12000] loss: 1.382\n",
            "tensor(22.5073)\n",
            "[2,  2000] loss: 1.269\n",
            "[2,  4000] loss: 1.232\n",
            "[2,  6000] loss: 1.204\n",
            "[2,  8000] loss: 1.147\n",
            "[2, 10000] loss: 1.106\n",
            "[2, 12000] loss: 1.083\n",
            "tensor(51.2795)\n",
            "[3,  2000] loss: 0.951\n",
            "[3,  4000] loss: 0.958\n",
            "[3,  6000] loss: 0.922\n",
            "[3,  8000] loss: 0.911\n",
            "[3, 10000] loss: 0.889\n",
            "[3, 12000] loss: 0.872\n",
            "tensor(34.7096)\n",
            "[4,  2000] loss: 0.757\n",
            "[4,  4000] loss: 0.762\n",
            "[4,  6000] loss: 0.767\n",
            "[4,  8000] loss: 0.756\n",
            "[4, 10000] loss: 0.733\n",
            "[4, 12000] loss: 0.723\n",
            "tensor(70.2413)\n",
            "[5,  2000] loss: 0.605\n",
            "[5,  4000] loss: 0.597\n",
            "[5,  6000] loss: 0.624\n",
            "[5,  8000] loss: 0.613\n",
            "[5, 10000] loss: 0.631\n",
            "[5, 12000] loss: 0.644\n",
            "tensor(50.7237)\n",
            "[6,  2000] loss: 0.471\n",
            "[6,  4000] loss: 0.515\n",
            "[6,  6000] loss: 0.521\n",
            "[6,  8000] loss: 0.541\n",
            "[6, 10000] loss: 0.508\n",
            "[6, 12000] loss: 0.537\n",
            "tensor(43.9823)\n",
            "[7,  2000] loss: 0.382\n",
            "[7,  4000] loss: 0.405\n",
            "[7,  6000] loss: 0.423\n",
            "[7,  8000] loss: 0.450\n",
            "[7, 10000] loss: 0.455\n",
            "[7, 12000] loss: 0.470\n",
            "tensor(68.9258)\n",
            "[8,  2000] loss: 0.293\n",
            "[8,  4000] loss: 0.326\n",
            "[8,  6000] loss: 0.360\n",
            "[8,  8000] loss: 0.356\n",
            "[8, 10000] loss: 0.385\n",
            "[8, 12000] loss: 0.392\n",
            "tensor(0.2006)\n",
            "[9,  2000] loss: 0.241\n",
            "[9,  4000] loss: 0.279\n",
            "[9,  6000] loss: 0.295\n",
            "[9,  8000] loss: 0.324\n",
            "[9, 10000] loss: 0.328\n",
            "[9, 12000] loss: 0.337\n",
            "tensor(196.9998)\n",
            "[10,  2000] loss: 0.202\n",
            "[10,  4000] loss: 0.227\n",
            "[10,  6000] loss: 0.243\n",
            "[10,  8000] loss: 0.273\n",
            "[10, 10000] loss: 0.258\n",
            "[10, 12000] loss: 0.276\n",
            "tensor(577.6006)\n",
            "[11,  2000] loss: 0.152\n",
            "[11,  4000] loss: 0.178\n",
            "[11,  6000] loss: 0.200\n",
            "[11,  8000] loss: 0.220\n",
            "[11, 10000] loss: 0.230\n",
            "[11, 12000] loss: 0.253\n",
            "tensor(0.1598)\n",
            "[12,  2000] loss: 0.140\n",
            "[12,  4000] loss: 0.165\n",
            "[12,  6000] loss: 0.179\n",
            "[12,  8000] loss: 0.196\n",
            "[12, 10000] loss: 0.200\n",
            "[12, 12000] loss: 0.215\n",
            "tensor(535.1991)\n",
            "[13,  2000] loss: 0.126\n",
            "[13,  4000] loss: 0.131\n",
            "[13,  6000] loss: 0.144\n",
            "[13,  8000] loss: 0.172\n",
            "[13, 10000] loss: 0.163\n",
            "[13, 12000] loss: 0.189\n",
            "tensor(0.0028)\n",
            "[14,  2000] loss: 0.100\n",
            "[14,  4000] loss: 0.124\n",
            "[14,  6000] loss: 0.140\n",
            "[14,  8000] loss: 0.129\n",
            "[14, 10000] loss: 0.162\n",
            "[14, 12000] loss: 0.167\n",
            "tensor(21.8389)\n",
            "[15,  2000] loss: 0.093\n",
            "[15,  4000] loss: 0.102\n",
            "[15,  6000] loss: 0.106\n",
            "[15,  8000] loss: 0.135\n",
            "[15, 10000] loss: 0.132\n",
            "[15, 12000] loss: 0.148\n",
            "tensor(4252.3960)\n",
            "[16,  2000] loss: 0.084\n",
            "[16,  4000] loss: 0.081\n",
            "[16,  6000] loss: 0.129\n",
            "[16,  8000] loss: 0.121\n",
            "[16, 10000] loss: 0.126\n",
            "[16, 12000] loss: 0.122\n",
            "tensor(0.0243)\n",
            "[17,  2000] loss: 0.057\n",
            "[17,  4000] loss: 0.073\n",
            "[17,  6000] loss: 0.106\n",
            "[17,  8000] loss: 0.122\n",
            "[17, 10000] loss: 0.119\n",
            "[17, 12000] loss: 0.113\n",
            "tensor(338.0668)\n",
            "[18,  2000] loss: 0.073\n",
            "[18,  4000] loss: 0.084\n",
            "[18,  6000] loss: 0.095\n",
            "[18,  8000] loss: 0.087\n",
            "[18, 10000] loss: 0.090\n",
            "[18, 12000] loss: 0.094\n",
            "tensor(0.0007)\n",
            "[19,  2000] loss: 0.062\n",
            "[19,  4000] loss: 0.066\n",
            "[19,  6000] loss: 0.089\n",
            "[19,  8000] loss: 0.099\n",
            "[19, 10000] loss: 0.077\n",
            "[19, 12000] loss: 0.103\n",
            "tensor(2.2072)\n",
            "[20,  2000] loss: 0.058\n",
            "[20,  4000] loss: 0.071\n",
            "[20,  6000] loss: 0.082\n",
            "[20,  8000] loss: 0.069\n",
            "[20, 10000] loss: 0.077\n",
            "[20, 12000] loss: 0.093\n",
            "tensor(810.6954)\n",
            "[21,  2000] loss: 0.076\n",
            "[21,  4000] loss: 0.059\n",
            "[21,  6000] loss: 0.061\n",
            "[21,  8000] loss: 0.099\n",
            "[21, 10000] loss: 0.078\n",
            "[21, 12000] loss: 0.097\n",
            "tensor(0.0050)\n",
            "[22,  2000] loss: 0.044\n",
            "[22,  4000] loss: 0.056\n",
            "[22,  6000] loss: 0.061\n",
            "[22,  8000] loss: 0.068\n",
            "[22, 10000] loss: 0.080\n",
            "[22, 12000] loss: 0.075\n",
            "tensor(137.1410)\n",
            "[23,  2000] loss: 0.040\n",
            "[23,  4000] loss: 0.042\n",
            "[23,  6000] loss: 0.037\n",
            "[23,  8000] loss: 0.062\n",
            "[23, 10000] loss: 0.071\n",
            "[23, 12000] loss: 0.064\n",
            "tensor(0.0149)\n",
            "[24,  2000] loss: 0.052\n",
            "[24,  4000] loss: 0.052\n",
            "[24,  6000] loss: 0.046\n",
            "[24,  8000] loss: 0.066\n",
            "[24, 10000] loss: 0.050\n",
            "[24, 12000] loss: 0.062\n",
            "tensor(0.0716)\n",
            "[25,  2000] loss: 0.037\n",
            "[25,  4000] loss: 0.038\n",
            "[25,  6000] loss: 0.049\n",
            "[25,  8000] loss: 0.062\n",
            "[25, 10000] loss: 0.056\n",
            "[25, 12000] loss: 0.070\n",
            "tensor(147.0275)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN_jG8Tmcz6m"
      },
      "source": [
        "* https://discuss.pytorch.org/t/check-the-norm-of-gradients/27961 <--reference * https://discuss.pytorch.org/t/how-to-get-gradient-of-loss/16955 <-- THIS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5d7R9KQvprB"
      },
      "source": [
        "    def __init__(self):\r\n",
        "      super(Convolutional, self).__init__()\r\n",
        "      self.layer1.add_module(\"Conv1\", nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1))\r\n",
        "      #self.layer1.add_module(\"BN1\", nn.BatchNorm2d(num_features=16, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True))\r\n",
        "      self.layer1.add_module(\"Relu1\", nn.ReLU(inplace=False))\r\n",
        "\r\n",
        "      self.pool = nn.MaxPool2d(2, 2)\r\n",
        "\r\n",
        "      self.layer2.add_module(\"Conv2\", nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, stride=2))\r\n",
        "      #self.layer2.add_module(\"BN2\", nn.BatchNorm2d(num_features=32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\r\n",
        "      self.layer2.add_module(\"Relu2\", nn.ReLU(inplace=False))\r\n",
        "     \r\n",
        "      self.fully_connected = nn.Linear(32 * 16 * 16, 10)\r\n",
        "     \r\n",
        "    def forward(self, x):\r\n",
        "      x = self.pool(self.layer1(x))\r\n",
        "      x = self.pool(self.layer2(x))\r\n",
        "      x = x.view(-1, 32 * 16 * 16)\r\n",
        "      x = self.fully_connected(x)\r\n",
        "      return x\r\n",
        "\r\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kT7I-f5qROH",
        "outputId": "37e41ce6-f46a-467f-9120-5566f588eba6"
      },
      "source": [
        "correct = 0\r\n",
        "total = 0\r\n",
        "with torch.no_grad():\r\n",
        "    for data in testloader:\r\n",
        "        images, labels = data\r\n",
        "        outputs = net(images)\r\n",
        "        _, predicted = torch.max(outputs.data, 1)\r\n",
        "        total += labels.size(0)\r\n",
        "        correct += (predicted == labels).sum().item()\r\n",
        "\r\n",
        "print('Accuracy of the network on the 10000 test images: %f %%' % (\r\n",
        "    100 * correct / total))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 75.510000 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuA8ig7Pqaix",
        "outputId": "e5a83968-0e7a-4a15-da1b-323c0feb7f4e"
      },
      "source": [
        "class_correct = list(0. for i in range(10))\r\n",
        "class_total = list(0. for i in range(10))\r\n",
        "with torch.no_grad():\r\n",
        "    for data in testloader:\r\n",
        "        images, labels = data\r\n",
        "        outputs = net(images)\r\n",
        "        _, predicted = torch.max(outputs, 1)\r\n",
        "        c = (predicted == labels).squeeze()\r\n",
        "        for i in range(4):\r\n",
        "            label = labels[i]\r\n",
        "            class_correct[label] += c[i].item()\r\n",
        "            class_total[label] += 1\r\n",
        "\r\n",
        "\r\n",
        "for i in range(10):\r\n",
        "    print('Accuracy of %5s : %2d %%' % (\r\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of plane : 82 %\n",
            "Accuracy of   car : 91 %\n",
            "Accuracy of  bird : 64 %\n",
            "Accuracy of   cat : 56 %\n",
            "Accuracy of  deer : 67 %\n",
            "Accuracy of   dog : 64 %\n",
            "Accuracy of  frog : 79 %\n",
            "Accuracy of horse : 84 %\n",
            "Accuracy of  ship : 82 %\n",
            "Accuracy of truck : 81 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8t21JGZyUr-"
      },
      "source": [
        "# 2. Residual connections (2 points)\n",
        "\n",
        "Please make use of the model code from Homework 4 question 2 as you work on this question.\n",
        "\n",
        "If your model didn't use residual connections, add them. If it already had residual connections, remove them. How does the performance change? Please experiment with applying residual connections around different blocks, where a block is a subset of layers (for example, add a residual connection around a single convolution/nonlinearity combination, or a residual connection around two convolution/nonlinearity combinations). Note that you may need to add 1x1 convolutions in the residual path if your block changes the shape (spatial or number of channels) of the input."
      ]
    }
  ]
}