{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "Copy of mxnet softmax regression example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnhqiIw4Zy_v"
      },
      "source": [
        "Full version of this code is at \n",
        "https://colab.research.google.com/github/d2l-ai/d2l-en-colab/blob/master/chapter_linear-networks/softmax-regression-scratch.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-Cz19dNYreL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d93fb10-6bee-4cd0-f56e-a673db768c38"
      },
      "source": [
        "!pip install d2l==0.16.1\n",
        "!pip install -U mxnet-cu101==1.7.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: d2l==0.16.1 in /usr/local/lib/python3.6/dist-packages (0.16.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from d2l==0.16.1) (1.1.5)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from d2l==0.16.1) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from d2l==0.16.1) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from d2l==0.16.1) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->d2l==0.16.1) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->d2l==0.16.1) (2018.9)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.16.1) (4.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.16.1) (5.3.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.16.1) (5.0.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.16.1) (5.6.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.16.1) (5.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l==0.16.1) (7.6.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.16.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.16.1) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l==0.16.1) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->d2l==0.16.1) (1.15.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->d2l==0.16.1) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->d2l==0.16.1) (4.3.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->d2l==0.16.1) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->d2l==0.16.1) (5.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.16.1) (0.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.16.1) (2.11.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.16.1) (5.1.2)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.16.1) (1.5.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.16.1) (4.7.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l==0.16.1) (0.9.2)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.16.1) (1.9.0)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.16.1) (22.0.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l==0.16.1) (2.6.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.16.1) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.16.1) (3.2.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.16.1) (1.4.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.16.1) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.16.1) (0.4.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l==0.16.1) (0.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->d2l==0.16.1) (1.0.18)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->d2l==0.16.1) (3.5.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->d2l==0.16.1) (1.0.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.16.1) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.16.1) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.16.1) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.16.1) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.16.1) (53.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->jupyter->d2l==0.16.1) (1.1.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->jupyter->d2l==0.16.1) (2.6.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l==0.16.1) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->d2l==0.16.1) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->d2l==0.16.1) (20.8)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->d2l==0.16.1) (0.2.5)\n",
            "Requirement already up-to-date: mxnet-cu101==1.7.0 in /usr/local/lib/python3.6/dist-packages (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101==1.7.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101==1.7.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101==1.7.0) (0.8.4)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 1,
        "tab": [
          "mxnet"
        ],
        "id": "r7Gb08TqYreL"
      },
      "source": [
        "# For automatically computing gradients of numpy functions\n",
        "from mxnet import autograd\n",
        "# mxnet's version of numpy, which is autograd-friendly\n",
        "from mxnet import np\n",
        "# mxnet's neural network + accelerator extensions for numpy\n",
        "from mxnet import npx\n",
        "# mxnet's neural network framework (only for data loading here)\n",
        "from mxnet import gluon\n",
        "# Tell mxnet to be as numpy-compatible as possible\n",
        "npx.set_np()\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36048xPFRifC"
      },
      "source": [
        "def filter_shirt_trousers(sample):\r\n",
        "    #if data is t-shirt\r\n",
        "    if sample[1] == 0:\r\n",
        "      return True\r\n",
        "    #if data is t-shirt\r\n",
        "    if sample[1] == 1:\r\n",
        "      return True\r\n",
        "    return False"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj56tI71d8Kd"
      },
      "source": [
        "def transform_shirt_trouser_label(data, label):\r\n",
        "    #if data is t-shirt\r\n",
        "    if label == 0:\r\n",
        "      return data, -1\r\n",
        "    #if data is t-shirt\r\n",
        "    if label == 1:\r\n",
        "      return data, 1\r\n",
        "    return data, label  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 4,
        "tab": [
          "mxnet"
        ],
        "id": "ICLAsWFMYreL"
      },
      "source": [
        "def load_data_fashion_mnist(batch_size=256, resize=None):\n",
        "    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\"\"\"\n",
        "    dataset = gluon.data.vision\n",
        "    trans = [dataset.transforms.ToTensor()]\n",
        "    if resize:\n",
        "        trans.insert(0, dataset.transforms.Resize(resize))\n",
        "    trans = dataset.transforms.Compose(trans)\n",
        "    mnist_train = dataset.FashionMNIST(train=True).transform_first(trans).filter(filter_shirt_trousers)\n",
        "    mnist_test = dataset.FashionMNIST(train=False).transform_first(trans).filter(filter_shirt_trousers)\n",
        "\n",
        "    mnist_train = mnist_train.transform(transform_shirt_trouser_label)\n",
        "    mnist_test = mnist_test.transform(transform_shirt_trouser_label)\n",
        "\n",
        "    return (gluon.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
        "                                  num_workers=4),\n",
        "            gluon.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
        "                                  num_workers=4))\n",
        "\n",
        "train_iter, test_iter = load_data_fashion_mnist()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 6,
        "tab": [
          "mxnet"
        ],
        "id": "zX3n5RaJYreM"
      },
      "source": [
        "num_inputs = 784\n",
        "#num_outputs = 10\n",
        "num_outputs = 2\n",
        "\n",
        "# Initialize values of parameters in typical numpy syntax\n",
        "W = np.random.normal(0, 0.01, (num_inputs, num_outputs))\n",
        "b = np.zeros(num_outputs)\n",
        "# Tell mxnet we want to keep track of gradients for these parameters\n",
        "W.attach_grad()\n",
        "b.attach_grad()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 13,
        "tab": [
          "mxnet"
        ],
        "id": "DwCOAF6mYreN"
      },
      "source": [
        "def softmax(X):\n",
        "    X_exp = np.exp(X)\n",
        "    partition = X_exp.sum(axis=1, keepdims=True)\n",
        "    return X_exp / partition  # The broadcasting mechanism is applied here"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 19,
        "tab": [
          "mxnet"
        ],
        "id": "8SHSZERyYreO"
      },
      "source": [
        "def net(X):\n",
        "    # Reshape is necessary because data is originally images\n",
        "    return softmax(np.dot(X.reshape((-1, W.shape[0])), W) + b)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 24,
        "tab": [
          "mxnet"
        ],
        "id": "lJG2Ayn0YreP"
      },
      "source": [
        "def cross_entropy(y_hat, y):\n",
        "    o = y_hat[range(len(y_hat)), y]\n",
        "    #for i in range(len(y)):\n",
        "    #  if y[i]==0:\n",
        "    #    y[i] = -1\n",
        "    return np.log(1+np.exp(-y * o))\n",
        "    #return - np.log(y_hat[range(len(y_hat)), y])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 27,
        "tab": [
          "mxnet"
        ],
        "id": "XNVx5-OdYreP"
      },
      "source": [
        "def accuracy(y_hat, y):  #@save\n",
        "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = y_hat.argmax(axis=1)\n",
        "    #print(y_hat)\n",
        "    #print(y)\n",
        "    for i in range(len(y_hat)):\n",
        "      if y_hat[i]==0:\n",
        "        y_hat[i] = -1\n",
        "    cmp = y_hat.astype(y.dtype) == y\n",
        "    print(float(cmp.astype(y.dtype).sum()))\n",
        "    return float(cmp.astype(y.dtype).sum())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 31,
        "tab": [
          "mxnet"
        ],
        "id": "FNrZRgXcYreQ"
      },
      "source": [
        "def evaluate_accuracy(net, data_iter):  #@save\n",
        "    \"\"\"Compute the accuracy for a model on a dataset.\"\"\"\n",
        "    metric = Accumulator(2)  # No. of correct predictions, no. of predictions\n",
        "    for X, y in data_iter:\n",
        "        metric.add(accuracy(net(X), y), y.size)\n",
        "    return metric[0] / metric[1]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 34,
        "tab": [
          "mxnet"
        ],
        "id": "-u8pWNwKYreQ"
      },
      "source": [
        "class Accumulator:  #@save\n",
        "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
        "    def __init__(self, n):\n",
        "        self.data = [0.0] * n\n",
        "\n",
        "    def add(self, *args):\n",
        "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
        "\n",
        "    def reset(self):\n",
        "        self.data = [0.0] * len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 38,
        "tab": [
          "mxnet"
        ],
        "id": "Vf1IWy4OYreQ"
      },
      "source": [
        "def train_epoch_ch3(net, train_iter, loss, updater):  #@save\n",
        "    \"\"\"Train a model within one epoch (defined in Chapter 3).\"\"\"\n",
        "    # Sum of training loss, sum of training accuracy, no. of examples\n",
        "    metric = Accumulator(3)\n",
        "    for X, y in train_iter:\n",
        "        # Compute gradients and update parameters\n",
        "        with autograd.record():\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y)\n",
        "        l.backward()\n",
        "        updater(X.shape[0])\n",
        "        metric.add(float(l.sum()), accuracy(y_hat, y), y.size)\n",
        "    # Return training loss and training accuracy\n",
        "    return metric[0] / metric[2], metric[1] / metric[2]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 44,
        "tab": [
          "mxnet"
        ],
        "id": "sHfUC4GgYreR"
      },
      "source": [
        "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):  #@save\n",
        "    for epoch in range(num_epochs):\n",
        "        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n",
        "        test_acc = evaluate_accuracy(net, test_iter)\n",
        "        train_loss, train_acc = train_metrics\n",
        "        print(f\"{epoch + 1}:\\ttrain {train_acc:0.2f}%\\ttest {test_acc:0.2f}%\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 46,
        "tab": [
          "mxnet"
        ],
        "id": "GYzcNBkUYreR"
      },
      "source": [
        "lr = 0.1\n",
        "\n",
        "def sgd(params, lr, batch_size):\n",
        "    \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
        "    for param in params:\n",
        "        param[:] = param - lr * param.grad / batch_size\n",
        "\n",
        "def updater(batch_size):\n",
        "    return sgd([W, b], lr, batch_size)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 49,
        "tab": [
          "mxnet"
        ],
        "id": "vmB9qBLLYreR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae0ce959-d55c-487d-e4b1-5d5958bf37c4"
      },
      "source": [
        "num_epochs = 100\n",
        "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127.0\n",
            "136.0\n",
            "133.0\n",
            "121.0\n",
            "119.0\n",
            "133.0\n",
            "146.0\n",
            "122.0\n",
            "128.0\n",
            "145.0\n",
            "127.0\n",
            "131.0\n",
            "145.0\n",
            "127.0\n",
            "171.0\n",
            "139.0\n",
            "136.0\n",
            "193.0\n",
            "189.0\n",
            "185.0\n",
            "215.0\n",
            "224.0\n",
            "212.0\n",
            "224.0\n",
            "226.0\n",
            "227.0\n",
            "238.0\n",
            "234.0\n",
            "226.0\n",
            "233.0\n",
            "231.0\n",
            "234.0\n",
            "241.0\n",
            "230.0\n",
            "241.0\n",
            "228.0\n",
            "241.0\n",
            "234.0\n",
            "242.0\n",
            "237.0\n",
            "229.0\n",
            "237.0\n",
            "236.0\n",
            "241.0\n",
            "233.0\n",
            "246.0\n",
            "208.0\n",
            "237.0\n",
            "239.0\n",
            "236.0\n",
            "244.0\n",
            "237.0\n",
            "245.0\n",
            "246.0\n",
            "194.0\n",
            "1:\ttrain 0.76%\ttest 0.94%\n",
            "242.0\n",
            "228.0\n",
            "238.0\n",
            "236.0\n",
            "242.0\n",
            "232.0\n",
            "238.0\n",
            "242.0\n",
            "239.0\n",
            "233.0\n",
            "238.0\n",
            "231.0\n",
            "238.0\n",
            "243.0\n",
            "243.0\n",
            "233.0\n",
            "239.0\n",
            "236.0\n",
            "244.0\n",
            "236.0\n",
            "242.0\n",
            "237.0\n",
            "240.0\n",
            "239.0\n",
            "239.0\n",
            "239.0\n",
            "240.0\n",
            "240.0\n",
            "242.0\n",
            "238.0\n",
            "249.0\n",
            "236.0\n",
            "245.0\n",
            "240.0\n",
            "237.0\n",
            "245.0\n",
            "246.0\n",
            "238.0\n",
            "241.0\n",
            "243.0\n",
            "232.0\n",
            "242.0\n",
            "247.0\n",
            "240.0\n",
            "238.0\n",
            "240.0\n",
            "210.0\n",
            "242.0\n",
            "242.0\n",
            "241.0\n",
            "247.0\n",
            "239.0\n",
            "247.0\n",
            "246.0\n",
            "196.0\n",
            "2:\ttrain 0.93%\ttest 0.95%\n",
            "242.0\n",
            "243.0\n",
            "238.0\n",
            "235.0\n",
            "238.0\n",
            "246.0\n",
            "243.0\n",
            "237.0\n",
            "241.0\n",
            "241.0\n",
            "230.0\n",
            "241.0\n",
            "238.0\n",
            "237.0\n",
            "237.0\n",
            "241.0\n",
            "239.0\n",
            "241.0\n",
            "243.0\n",
            "247.0\n",
            "242.0\n",
            "238.0\n",
            "241.0\n",
            "245.0\n",
            "240.0\n",
            "241.0\n",
            "238.0\n",
            "237.0\n",
            "239.0\n",
            "248.0\n",
            "241.0\n",
            "246.0\n",
            "240.0\n",
            "246.0\n",
            "248.0\n",
            "243.0\n",
            "248.0\n",
            "246.0\n",
            "249.0\n",
            "238.0\n",
            "245.0\n",
            "242.0\n",
            "238.0\n",
            "237.0\n",
            "232.0\n",
            "244.0\n",
            "218.0\n",
            "243.0\n",
            "242.0\n",
            "243.0\n",
            "247.0\n",
            "239.0\n",
            "246.0\n",
            "246.0\n",
            "196.0\n",
            "3:\ttrain 0.94%\ttest 0.95%\n",
            "245.0\n",
            "242.0\n",
            "244.0\n",
            "244.0\n",
            "240.0\n",
            "243.0\n",
            "247.0\n",
            "240.0\n",
            "235.0\n",
            "243.0\n",
            "245.0\n",
            "239.0\n",
            "246.0\n",
            "241.0\n",
            "246.0\n",
            "246.0\n",
            "241.0\n",
            "242.0\n",
            "236.0\n",
            "243.0\n",
            "244.0\n",
            "242.0\n",
            "242.0\n",
            "242.0\n",
            "238.0\n",
            "249.0\n",
            "243.0\n",
            "241.0\n",
            "244.0\n",
            "246.0\n",
            "240.0\n",
            "239.0\n",
            "243.0\n",
            "242.0\n",
            "239.0\n",
            "233.0\n",
            "240.0\n",
            "241.0\n",
            "245.0\n",
            "242.0\n",
            "240.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}